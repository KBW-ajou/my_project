{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 착지 파일 업로드\n",
    "landing_df = pd.read_csv('착지.csv')\n",
    "\n",
    "# 주문 파일 업로드\n",
    "order_mon_df = pd.read_csv('주문_월요일.csv')\n",
    "order_tue_df = pd.read_csv('주문_화요일.csv')\n",
    "order_wed_df = pd.read_csv('주문_수요일.csv')\n",
    "order_thu_df = pd.read_csv('주문_목요일.csv')\n",
    "order_fri_df = pd.read_csv('주문_금요일.csv')\n",
    "order_sat_df = pd.read_csv('주문_토요일.csv')\n",
    "\n",
    "# OD Matrix 파일 업로드\n",
    "OD_csv = pd.read_csv('updated_OD_Matrix_corrected 3.csv')\n",
    "\n",
    "# 센터 파일 업로드\n",
    "center = pd.read_csv('센터.csv')\n",
    "\n",
    "# 차량 파일 업로드 \n",
    "vehicle = pd.read_csv('차량정보.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통합 주문 데이터프레임\n",
    "order_dfs = [order_mon_df, order_tue_df, order_wed_df, order_thu_df, order_fri_df, order_sat_df ]\n",
    "order_df = pd.concat(order_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "착지 테이블과 주문 테이블 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID와 Stop_ID를 기준으로 병합\n",
    "integration_mon_df = pd.merge(landing_df[:], order_mon_df[:], left_on='ID', right_on='Stop_ID')\n",
    "integration_tue_df = pd.merge(landing_df[:], order_tue_df[:], left_on='ID', right_on='Stop_ID')\n",
    "integration_wed_df = pd.merge(landing_df[:], order_wed_df[:], left_on='ID', right_on='Stop_ID')\n",
    "integration_thu_df = pd.merge(landing_df[:], order_thu_df[:], left_on='ID', right_on='Stop_ID')\n",
    "integration_fri_df = pd.merge(landing_df[:], order_fri_df[:], left_on='ID', right_on='Stop_ID')\n",
    "integration_sat_df = pd.merge(landing_df[:], order_sat_df[:], left_on='ID', right_on='Stop_ID')\n",
    "\n",
    "# 불필요한 열 제거 (Y_y, X_y만 제거, Stop_ID는 Order_ID와 함께 유지)\n",
    "integration_mon_df = integration_mon_df.drop(columns=['Y_y', 'X_y'])\n",
    "integration_tue_df = integration_tue_df.drop(columns=['Y_y', 'X_y'])\n",
    "integration_wed_df = integration_wed_df.drop(columns=['Y_y', 'X_y'])\n",
    "integration_thu_df = integration_thu_df.drop(columns=['Y_y', 'X_y'])\n",
    "integration_fri_df = integration_fri_df.drop(columns=['Y_y', 'X_y'])\n",
    "integration_sat_df = integration_sat_df.drop(columns=['Y_y', 'X_y'])\n",
    "\n",
    "# 열 이름 변경\n",
    "integration_mon_df = integration_mon_df.rename(columns={'Y_x': 'Y', 'X_x': 'X'})\n",
    "integration_tue_df = integration_tue_df.rename(columns={'Y_x': 'Y', 'X_x': 'X'})\n",
    "integration_wed_df = integration_wed_df.rename(columns={'Y_x': 'Y', 'X_x': 'X'})\n",
    "integration_thu_df = integration_thu_df.rename(columns={'Y_x': 'Y', 'X_x': 'X'})\n",
    "integration_fri_df = integration_fri_df.rename(columns={'Y_x': 'Y', 'X_x': 'X'})\n",
    "integration_sat_df = integration_sat_df.rename(columns={'Y_x': 'Y', 'X_x': 'X'})\n",
    "\n",
    "# 열 순서 재정렬\n",
    "cols_1 = ['Order_ID', 'ID'] + [col for col in integration_mon_df.columns if col not in ['Order_ID', 'ID']]\n",
    "cols_2 = ['Order_ID', 'ID'] + [col for col in integration_tue_df.columns if col not in ['Order_ID', 'ID']]\n",
    "cols_3 = ['Order_ID', 'ID'] + [col for col in integration_wed_df.columns if col not in ['Order_ID', 'ID']]\n",
    "cols_4 = ['Order_ID', 'ID'] + [col for col in integration_thu_df.columns if col not in ['Order_ID', 'ID']]\n",
    "cols_5 = ['Order_ID', 'ID'] + [col for col in integration_fri_df.columns if col not in ['Order_ID', 'ID']]\n",
    "cols_6 = ['Order_ID', 'ID'] + [col for col in integration_sat_df.columns if col not in ['Order_ID', 'ID']]\n",
    "\n",
    "integration_mon_df = integration_mon_df[cols_1]\n",
    "integration_tue_df = integration_tue_df[cols_2]\n",
    "integration_wed_df = integration_wed_df[cols_3]\n",
    "integration_thu_df = integration_thu_df[cols_4]\n",
    "integration_fri_df = integration_fri_df[cols_5]\n",
    "integration_sat_df = integration_sat_df[cols_6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "진입제한이 1000인 테이블, 진입제한이 1000이 넘으면서 무게가 3000을 안 넘는 테이블, 진입제한이 1000을 넘으면서 무게가 3000을 넘는 테이블로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_mon_df = integration_mon_df[integration_mon_df['Access_restriction'] == 1000]\n",
    "one_tue_df = integration_tue_df[integration_tue_df['Access_restriction'] == 1000]\n",
    "one_wed_df = integration_wed_df[integration_wed_df['Access_restriction'] == 1000]\n",
    "one_thu_df = integration_thu_df[integration_thu_df['Access_restriction'] == 1000]\n",
    "one_fri_df = integration_fri_df[integration_fri_df['Access_restriction'] == 1000]\n",
    "one_sat_df = integration_sat_df[integration_sat_df['Access_restriction'] == 1000]\n",
    "else_mon_df = integration_mon_df[integration_mon_df['Access_restriction'] != 1000]\n",
    "else_tue_df = integration_tue_df[integration_tue_df['Access_restriction'] != 1000]\n",
    "else_wed_df = integration_wed_df[integration_wed_df['Access_restriction'] != 1000]\n",
    "else_thu_df = integration_thu_df[integration_thu_df['Access_restriction'] != 1000]\n",
    "else_fri_df = integration_fri_df[integration_fri_df['Access_restriction'] != 1000]\n",
    "else_sat_df = integration_sat_df[integration_sat_df['Access_restriction'] != 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_mon_df = else_mon_df[(else_mon_df['weight'] <= 3500) & (else_mon_df['plt'] <= 8)]\n",
    "three_tue_df = else_tue_df[(else_tue_df['weight'] <= 3500) & (else_tue_df['plt'] <= 8)]\n",
    "three_wed_df = else_wed_df[(else_wed_df['weight'] <= 3500) & (else_wed_df['plt'] <= 8)]\n",
    "three_thu_df = else_thu_df[(else_thu_df['weight'] <= 3500) & (else_thu_df['plt'] <= 8)]\n",
    "three_fri_df = else_fri_df[(else_fri_df['weight'] <= 3500) & (else_fri_df['plt'] <= 8)]\n",
    "three_sat_df = else_sat_df[(else_sat_df['weight'] <= 3500) & (else_sat_df['plt'] <= 8)]\n",
    "eleven_mon_df = else_mon_df[(else_mon_df['weight'] > 3500) | (else_mon_df['plt'] > 8)]\n",
    "eleven_tue_df = else_tue_df[(else_tue_df['weight'] > 3500) | (else_tue_df['plt'] > 8)]\n",
    "eleven_wed_df = else_wed_df[(else_wed_df['weight'] > 3500) | (else_wed_df['plt'] > 8)]\n",
    "eleven_thu_df = else_thu_df[(else_thu_df['weight'] > 3500) | (else_thu_df['plt'] > 8)]\n",
    "eleven_fri_df = else_fri_df[(else_fri_df['weight'] > 3500) | (else_fri_df['plt'] > 8)]\n",
    "eleven_sat_df = else_sat_df[(else_sat_df['weight'] > 3500) | (else_sat_df['plt'] > 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클러스터링 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(order_df, num_cluster):\n",
    "    # Step 1: 착지 파일에서 Start_time과 End_time을 기준으로 클러스터링 (4개 클러스터)\n",
    "    kmeans_time = KMeans(n_clusters=4, random_state=42)\n",
    "    landing_df['Cluster_time'] = kmeans_time.fit_predict(landing_df[['Start_time', 'End_time']])\n",
    "\n",
    "    # Step 2: 각 클러스터별로 ID 리스트를 생성\n",
    "    cluster_id_lists = [[] for _ in range(4)]\n",
    "    for cluster_num in range(4):\n",
    "        cluster_id_lists[cluster_num] = landing_df[landing_df['Cluster_time'] == cluster_num]['ID'][:].tolist()\n",
    "\n",
    "    # Step 3: 주문 파일에서 각 클러스터 리스트의 ID와 Stop_ID를 매칭하여 클러스터별로 데이터 분리 및 클러스터링\n",
    "    location_cluster_dfs = []\n",
    "    for cluster_num, id_list in enumerate(cluster_id_lists):\n",
    "        cluster_time = order_df[order_df['Stop_ID'].isin(id_list)].copy()\n",
    "        \n",
    "        # Step 4: 각 클러스터 내에서 X와 Y를 기준으로 다시 클러스터링 (예: num_cluster 개 클러스터)\n",
    "        kmeans_location = KMeans(n_clusters=num_cluster, random_state=42)\n",
    "        cluster_time['Cluster_location'] = kmeans_location.fit_predict(cluster_time[['X', 'Y']])\n",
    "        \n",
    "        # 각 위치 클러스터별 데이터프레임을 저장할 리스트\n",
    "        cluster_location_dfs = []\n",
    "        for inner_cluster_num in range(num_cluster):\n",
    "            cluster_location_df = cluster_time[cluster_time['Cluster_location'] == inner_cluster_num].copy()\n",
    "            cluster_location_dfs.append(cluster_location_df)\n",
    "        \n",
    "        # 각 시간별 클러스터에 해당하는 위치별 클러스터 데이터프레임을 저장\n",
    "        location_cluster_dfs.append(cluster_location_dfs)\n",
    "    \n",
    "    return location_cluster_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_cluster_1 = clustering(one_mon_df, 2)\n",
    "tue_cluster_1 = clustering(one_tue_df, 2)\n",
    "wed_cluster_1 = clustering(one_wed_df, 2)\n",
    "thu_cluster_1 = clustering(one_thu_df, 2)\n",
    "fri_cluster_1 = clustering(one_fri_df, 2)\n",
    "sat_cluster_1 = clustering(one_sat_df, 2)\n",
    "mon_cluster_3 = clustering(three_mon_df, 7)\n",
    "tue_cluster_3 = clustering(three_tue_df, 7)\n",
    "wed_cluster_3 = clustering(three_wed_df, 7)\n",
    "thu_cluster_3 = clustering(three_thu_df, 7)\n",
    "fri_cluster_3 = clustering(three_fri_df, 7)\n",
    "sat_cluster_3 = clustering(three_sat_df, 4)\n",
    "mon_cluster_11 = clustering(eleven_mon_df, 2)\n",
    "tue_cluster_11 = clustering(eleven_tue_df, 2)\n",
    "wed_cluster_11 = clustering(eleven_wed_df, 2)\n",
    "thu_cluster_11 = clustering(eleven_thu_df, 2)\n",
    "fri_cluster_11 = clustering(eleven_fri_df, 2)\n",
    "sat_cluster_11 = clustering(eleven_sat_df, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "착지별 OD Matrix 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OD_Matrix(Bin):\n",
    "    # OriginID와 DestinationID 리스트\n",
    "    origin_ids = Bin[:]\n",
    "    destination_ids = Bin[:]\n",
    "\n",
    "    # 리스트에 termianl 추가\n",
    "    origin_ids.append('Terminal')\n",
    "    destination_ids.append('Terminal')\n",
    "\n",
    "    # 데이터를 필터링하여 필요한 OriginID와 DestinationID만 남기기\n",
    "    filtered_data = OD_csv[(OD_csv['OriginID'].isin(origin_ids)) & OD_csv['DestinationID'].isin(destination_ids)]\n",
    "\n",
    "    # 피벗 테이블을 사용하여 2차원 OD Matrix 만들기 (Total_Time 기준)\n",
    "    od_time = filtered_data.pivot(index='OriginID', columns='DestinationID', values='Total_Time')\n",
    "    od_distance = filtered_data.pivot(index='OriginID', columns='DestinationID', values='Total_Distance')\n",
    "\n",
    "    return od_distance, od_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin 생성 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_make_bin(cluster, max_weight, max_plt, MaxCount):\n",
    "    # 각 Stop_ID에 해당하는 Order_ID 리스트와 총 무게, total_plt를 계산하여 데이터프레임 생성\n",
    "    stop_order_map = cluster.groupby('Stop_ID')['Order_ID'].apply(list).reset_index()\n",
    "    stop_order_map['total_weight'] = cluster.groupby('Stop_ID')['weight'].sum().values\n",
    "    stop_order_map['total_plt'] = cluster.groupby('Stop_ID')['plt'].sum().values\n",
    "\n",
    "    # total_weight를 기준으로 내림차순 정렬하여 무거운 주문부터 처리\n",
    "    stop_order_map = stop_order_map.sort_values(by='total_weight', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    grouped_orders = []  # 그룹화된 주문을 저장할 리스트\n",
    "    grouped_stop_ids = []  # 그룹화된 Stop_ID를 저장할 리스트\n",
    "    group_weights = []  # 각 그룹의 총 무게 리스트 (이차원 리스트)\n",
    "    group_plts = []  # 각 그룹의 총 팔레트 수 리스트 (이차원 리스트)\n",
    "    \n",
    "    current_group = []   # 현재 그룹의 주문을 저장할 리스트\n",
    "    current_stop_ids = []  # 현재 그룹의 Stop_ID를 저장할 리스트\n",
    "    current_weight = 0   # 현재 그룹의 총 무게를 저장할 변수\n",
    "    current_plt = 0      # 현재 그룹의 총 팔레트 수를 저장할 변수\n",
    "    not_check_orders = list(cluster['Order_ID'])  # 처리되지 않은 주문 ID 리스트\n",
    "    \n",
    "    while not_check_orders:  # not_check_orders 리스트가 비어있지 않은 동안 루프를 계속 실행. 즉, 처리되지 않은 주문이 남아 있는 한 계속 실행\n",
    "        any_order_processed = False # 루프가 한 번이라도 실행되는지 확인하기 위한 플래그 변수 초기화\n",
    "        \n",
    "        for idx, row in stop_order_map.iterrows():  # stop_order_map의 각 행을 순회하며 Stop_ID와 Order_ID를 가져옴\n",
    "            stop_id = row['Stop_ID']\n",
    "            orders = row['Order_ID']\n",
    "            \n",
    "            # 같은 착지의 주문들은 무조건 같은 그룹에 포함\n",
    "            group_weight = sum(cluster[cluster['Order_ID'].isin(orders)]['weight']) # orders 리스트에 포함된 주문들의 총 무게를 계산하여 group_weight 변수에 저장\n",
    "            group_plt = sum(cluster[cluster['Order_ID'].isin(orders)]['plt']) # orders 리스트에 포함된 주문들의 총 팔레트 수를 계산하여 group_plt 변수에 저장\n",
    "            \n",
    "            if group_weight > max_weight or group_plt > max_plt:\n",
    "                # 큰 주문들을 나눠서 처리\n",
    "                order_details = cluster[cluster['Order_ID'].isin(orders)][['Order_ID', 'weight', 'plt']].values.tolist()\n",
    "                order_details.sort(key=lambda x: (-x[1], -x[2])) # 무게와 팔레트 수로 내림차순 정렬\n",
    "                \n",
    "                temp_group = []\n",
    "                temp_weight = 0\n",
    "                temp_plt = 0\n",
    "                \n",
    "                for order in order_details:\n",
    "                    if temp_weight + order[1] > max_weight or temp_plt + order[2] > max_plt:\n",
    "                        if temp_group:\n",
    "                            grouped_orders.append([temp_group])\n",
    "                            grouped_stop_ids.append([stop_id])\n",
    "                            group_weights.append([temp_weight])\n",
    "                            group_plts.append([temp_plt])\n",
    "                            temp_group = []\n",
    "                            temp_weight = 0\n",
    "                            temp_plt = 0\n",
    "                    temp_group.append(order[0])\n",
    "                    temp_weight += order[1]\n",
    "                    temp_plt += order[2]\n",
    "                    if order[0] in not_check_orders:\n",
    "                        not_check_orders.remove(order[0])\n",
    "                \n",
    "                if temp_group:\n",
    "                    grouped_orders.append([temp_group])\n",
    "                    grouped_stop_ids.append([stop_id])\n",
    "                    group_weights.append([temp_weight])\n",
    "                    group_plts.append([temp_plt])\n",
    "                \n",
    "                any_order_processed = True\n",
    "                \n",
    "            else:\n",
    "                if (current_weight + group_weight <= max_weight and \n",
    "                    current_plt + group_plt <= max_plt and \n",
    "                    len(current_stop_ids) + 1 <= MaxCount): # 현재 그룹에 새로운 주문들을 추가했을 때, 최대 무게, 최대 팔레트 수 및 최대 착지 수를 초과하지 않는지 확인\n",
    "                    current_group.append(orders) # orders 리스트의 주문들을 current_group에 추가\n",
    "                    current_weight += group_weight \n",
    "                    current_plt += group_plt\n",
    "                    if stop_id not in current_stop_ids: # 현재 그룹에 stop_id가 포함되어 있지 않다면 current_stop_ids에 추가\n",
    "                        current_stop_ids.append(stop_id)\n",
    "                    for order in orders:\n",
    "                        if order in not_check_orders: # 주문이 not_check_orders에 있으면\n",
    "                            not_check_orders.remove(order) # not_check_orders에서 주문을 제거\n",
    "                    any_order_processed = True\n",
    "            \n",
    "            if current_weight >= max_weight or current_plt >= max_plt or len(current_stop_ids) >= MaxCount: \n",
    "                # 현재 그룹의 총 무게가 최대 무게에 도달하거나, 총 팔레트 수가 최대 팔레트 수에 도달했거나, 착지 수가 최대 착지 수에 도달했는지 확인\n",
    "                break # 이 조건이 참이면, 더 이상 현재 그룹에 주문을 추가하지 않기 위해 반복문을 종료\n",
    "        \n",
    "        # 현재 그룹을 저장하고 새로운 그룹 시작\n",
    "        if any_order_processed: # 이번 루프에서 주문이 추가되었는지 확인해서 만약 하나라도 추가된 경우, 현재 그룹을 저장하고 새로운 그룹을 시작\n",
    "            stop_weights = [sum(cluster[(cluster['Stop_ID'] == sid) & (cluster['Order_ID'].isin(sum(current_group, [])))]['weight']) for sid in current_stop_ids]\n",
    "            stop_plts = [sum(cluster[(cluster['Stop_ID'] == sid) & (cluster['Order_ID'].isin(sum(current_group, [])))]['plt']) for sid in current_stop_ids]\n",
    "            grouped_orders.append(current_group)\n",
    "            grouped_stop_ids.append(current_stop_ids)\n",
    "            group_weights.append(stop_weights)\n",
    "            group_plts.append(stop_plts)\n",
    "            current_group = [] # current_group을 초기화하여 새로운 그룹을 시작할 준비\n",
    "            current_stop_ids = [] # current_stop_ids를 초기화하여 새로운 그룹을 시작할 준비\n",
    "            current_weight = 0 # current_weight 초기화\n",
    "            current_plt = 0 # current_plt 초기화\n",
    "            \n",
    "            # stop_order_map에서 이미 처리된 주문을 제거\n",
    "            # apply 함수로 각 Order_ID 리스트가 not_check_orders에 없는 경우를 필터링\n",
    "            stop_order_map = stop_order_map[~stop_order_map['Order_ID'].apply(lambda x: all(order not in not_check_orders for order in x))]\n",
    "            stop_order_map.reset_index(drop=True, inplace=True) # stop_order_map의 인덱스를 재설정하고, drop=True로 기존 인덱스를 제거\n",
    "        \n",
    "        # 무한 루프 방지: 주문이 제거되지 않은 경우 루프를 탈출\n",
    "        if not any_order_processed:\n",
    "            break\n",
    "\n",
    "    # 남은 그룹 추가\n",
    "    if current_group: # 현재 그룹에 주문이 남아 있는 경우, 이 그룹을 저장\n",
    "        stop_weights = [sum(cluster[(cluster['Stop_ID'] == sid) & (cluster['Order_ID'].isin(sum(current_group, [])))]['weight']) for sid in current_stop_ids]\n",
    "        stop_plts = [sum(cluster[(cluster['Stop_ID'] == sid) & (cluster['Order_ID'].isin(sum(current_group, [])))]['plt']) for sid in current_stop_ids]\n",
    "        grouped_orders.append(current_group)\n",
    "        grouped_stop_ids.append(current_stop_ids)\n",
    "        group_weights.append(stop_weights)\n",
    "        group_plts.append(stop_plts)\n",
    "\n",
    "    # grouped_orders를 3차원 리스트로 변환 (Stop_ID 기준으로 나누기)\n",
    "    final_grouped_orders = []\n",
    "    for group in grouped_orders:\n",
    "        temp_group = []\n",
    "        for stop_id_list in group:\n",
    "            temp_group.append(stop_id_list)\n",
    "        final_grouped_orders.append(temp_group)\n",
    "\n",
    "    return final_grouped_orders, grouped_stop_ids, group_weights, group_plts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_cal(current_time, add_min = 0, plt = 0):\n",
    "    # 현재 시간을 시와 분으로 분리\n",
    "    current_hour = int(current_time)\n",
    "    current_min = (current_time - current_hour)*100 \n",
    "\n",
    "    add_time_hour = add_min //60\n",
    "    add_time_min = add_min % 60 \n",
    "    \n",
    "    # plt의 개수당 10분을 추가\n",
    "    additional_minutes = (plt * 10) % 60 \n",
    "    additional_houres = (plt * 10) // 60\n",
    "\n",
    "    # 총 분 계산 (기존 분 + 추가할 분 + plt에 의한 추가 분)\n",
    "    new_time_hour = current_hour + add_time_hour + additional_houres\n",
    "    new_time_min = current_min + add_time_min + additional_minutes\n",
    "    new_time = new_time_hour + (new_time_min // 60) + (new_time_min % 60 /100)\n",
    "        \n",
    "    return new_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이동시간, 이동거리 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_time(route, od_time):\n",
    "    path = route.copy()\n",
    "    path.insert(0,'Terminal')\n",
    "    path.append('Terminal')\n",
    "    moving_time_tmp = 0\n",
    "    for i in range(len(path) - 1):\n",
    "        moving_time_tmp += od_time.loc[path[i], path[i + 1]]\n",
    "    out_time_tmp = od_time.loc[path[0], path[1]]  # 터미널에서 첫 착지로 이동하는데 걸린 시간\n",
    "    in_time_tmp = od_time.loc[path[-2], path[-1]]  # 마지막 착지에서 터미널로 복귀하는데 걸린 시간\n",
    "    working_time_tmp = moving_time_tmp - (out_time_tmp + in_time_tmp)  # 움직이는 총 시간\n",
    "    moving_time = min_cal(0, moving_time_tmp, 0)\n",
    "    working_time = min_cal(0, working_time_tmp, 0)\n",
    "    out_time = min_cal(0, out_time_tmp, 0)\n",
    "    in_time = min_cal(0, in_time_tmp, 0)\n",
    "    return moving_time, working_time, out_time, in_time\n",
    "\n",
    "def route_distance(route, od_distance):\n",
    "    path = route.copy()\n",
    "    path.insert(0,'Terminal')\n",
    "    path.append('Terminal')\n",
    "    distance = 0\n",
    "    for i in range(len(path)-1):\n",
    "        distance += od_distance.loc[path[i],path[i+1]]\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하차시간 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unloading_time(stop_id_list, plt_list): # plt에 따른 하차하는데 걸린 시간(분) (고정시간+변동시간)\n",
    "    tmp = 0\n",
    "    for i in range(len(stop_id_list)):\n",
    "        tmp += 5\n",
    "    for i in range(len(plt_list)):\n",
    "        tmp += plt_list[i]*10\n",
    "    unloading_time = tmp\n",
    "    return unloading_time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라우팅 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기해(근사 최적해)를 구하는 Nearest Neighbor 알고리즘\n",
    "def nearest_neighbor(matrix):\n",
    "    start_node = 'Terminal'\n",
    "    n = len(matrix)\n",
    "    visited = {node: False for node in matrix.index}\n",
    "    path = [start_node]\n",
    "    current_node = start_node\n",
    "    visited[current_node] = True\n",
    "\n",
    "    while len(path) < n:\n",
    "        current_index = current_node\n",
    "        next_node = None\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        for node in matrix.index:\n",
    "            if not visited[node] and matrix.loc[current_index, node] < min_distance:\n",
    "                min_distance = matrix.loc[current_index, node]\n",
    "                next_node = node\n",
    "        \n",
    "        if next_node is None:\n",
    "            break\n",
    "        \n",
    "        path.append(next_node)\n",
    "        visited[next_node] = True\n",
    "        current_node = next_node\n",
    "    path.append('Terminal')\n",
    "    return path\n",
    "\n",
    "\n",
    "# 초기해의 꼬인 경로를 푸는 알고리즘\n",
    "def two_opt(path, matrix):\n",
    "    def path_cost(path):\n",
    "        cost = 0\n",
    "        for i in range(len(path) - 1):\n",
    "            cost += matrix.loc[path[i], path[i + 1]]\n",
    "        return cost\n",
    "\n",
    "    improved = True\n",
    "    max_no_improve = 10  # 개선이 없을 때 최대 반복 횟수\n",
    "    no_improve_count = 0\n",
    "\n",
    "    while improved and no_improve_count < max_no_improve:\n",
    "        improved = False\n",
    "        for i in range(1, len(path) - 2):\n",
    "            for j in range(i + 1, len(path)):\n",
    "                if j - i == 1: \n",
    "                    continue\n",
    "                new_path = path[:i] + path[i:j][::-1] + path[j:]\n",
    "                if path_cost(new_path) < path_cost(path):\n",
    "                    path = new_path\n",
    "                    improved = True\n",
    "                    no_improve_count = 0  # 개선이 있으면 카운터 초기화\n",
    "        if not improved:\n",
    "            no_improve_count += 1  # 개선이 없으면 카운터 증가\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간 제약에 따른 빈 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bin_Slicing(grouped_orders, grouped_stop_ids, group_weights, group_plts, time_windows): \n",
    "    grouped_stop_ids_list = grouped_stop_ids.copy()\n",
    "    grouped_order_list = grouped_orders.copy()\n",
    "    group_weights_list = group_weights.copy()\n",
    "    group_plts_list = group_plts.copy()\n",
    "    \n",
    "    new_bin_list = []\n",
    "    new_order_list = []\n",
    "    new_weight_list = []\n",
    "    new_plt_list = []\n",
    "    \n",
    "    new_moving_time_list = []\n",
    "    new_working_time_list = []\n",
    "    new_out_time_list = []\n",
    "    new_in_time_list = []\n",
    "    continue_check = True\n",
    "\n",
    "    while grouped_stop_ids_list:  # 리스트에 요소가 남아있는 동안 반복\n",
    "        \n",
    "        if not grouped_order_list or not group_weights_list or not group_plts_list:\n",
    "            break\n",
    "\n",
    "        tmp_orders = grouped_order_list.pop(0)\n",
    "        tmp_stop_ids = grouped_stop_ids_list.pop(0)  # 첫 번째 원소를 가져와서 제거\n",
    "        tmp_weights = group_weights_list.pop(0)\n",
    "        tmp_plts = group_plts_list.pop(0)\n",
    "\n",
    "        for j in range(len(tmp_stop_ids)-1, -1, -1):\n",
    "            tmp_orders_range = tmp_orders[:j+1]\n",
    "            tmp_stop_ids_range = tmp_stop_ids[:j+1]\n",
    "            tmp_weights_range = tmp_weights[:j+1]\n",
    "            tmp_plts_range = tmp_plts[:j+1]\n",
    "\n",
    "            od_distance, od_time = OD_Matrix(tmp_stop_ids_range)\n",
    "            initial_path = nearest_neighbor(od_distance)\n",
    "            optimized_path = two_opt(initial_path, od_distance)\n",
    "            time_moving, time_working, time_out, time_in = moving_time(optimized_path, od_time) \n",
    "            unload_time = unloading_time(tmp_stop_ids_range, tmp_plts_range)\n",
    "            total_time_working = min_cal(time_working, unload_time, 0)\n",
    "\n",
    "            if total_time_working <= time_windows:\n",
    "                \n",
    "                new_order_list.append(tmp_orders[:j+1])\n",
    "                new_bin_list.append(tmp_stop_ids[:j+1])\n",
    "                new_weight_list.append(tmp_weights[:j+1])\n",
    "                new_plt_list.append(tmp_plts[:j+1])\n",
    "\n",
    "                distance, time = OD_Matrix(tmp_stop_ids[:j+1])\n",
    "                initial = nearest_neighbor(distance)\n",
    "                optimized = two_opt(initial, distance)\n",
    "                new_time_moving, new_time_working, new_time_out, new_time_in = moving_time(optimized, time)\n",
    "                new_unload_time = unloading_time(tmp_stop_ids_range, tmp_plts_range)\n",
    "                new_total_time_working = min_cal(new_time_working, new_unload_time, 0)\n",
    "\n",
    "                new_moving_time_list.append(new_time_moving)\n",
    "                new_working_time_list.append(new_total_time_working)\n",
    "                new_out_time_list.append(new_time_out)\n",
    "                new_in_time_list.append(new_time_in)\n",
    "                \n",
    "                if j+1 < len(tmp_stop_ids):  # 남은 원소가 있는 경우만 추가\n",
    "                    grouped_order_list.append(tmp_orders[j+1:])\n",
    "                    grouped_stop_ids_list.append(tmp_stop_ids[j+1:])\n",
    "                    group_weights_list.append(tmp_weights[j+1:])\n",
    "                    group_plts_list.append(tmp_plts[j+1:])\n",
    "                break\n",
    "            \n",
    "    # orders = []\n",
    "    # for outer in new_order_list:\n",
    "    #     temp_list = []\n",
    "    #     for inner in outer:\n",
    "    #         temp_list.extend(inner)\n",
    "    #     orders.append(temp_list)\n",
    "    if grouped_stop_ids == new_bin_list:\n",
    "            continue_check = False\n",
    "\n",
    "    return  new_bin_list, new_order_list, new_weight_list, new_plt_list, new_moving_time_list, new_working_time_list, new_out_time_list, new_in_time_list, continue_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로세스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_bin(cluster, num):\n",
    "    # final_df = pd.DataFrame(columns=['Stop_list', 'weight', 'plt', 'moving_time', 'working_time', 'out_time', 'in_time', 'time_cluster', 'time_start', 'time_end'])\n",
    "    final_df = pd.DataFrame(columns=['Stop_list', 'Order_list', 'weight', 'plt', 'moving_time', 'working_time', 'out_time', 'in_time', 'time_cluster', 'time_start', 'time_end'])\n",
    "    row = []\n",
    "    if num == 1:\n",
    "        veh_ton = 1000\n",
    "        veh_plt = 2.8\n",
    "        veh_count = 25\n",
    "    elif num == 3:\n",
    "        veh_ton = 3500\n",
    "        veh_plt = 8\n",
    "        veh_count = 15\n",
    "    else:\n",
    "        veh_ton = 11000\n",
    "        veh_plt = 16\n",
    "        veh_count = 5\n",
    "    \n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            time_start = 5\n",
    "            time_end = 10\n",
    "            time_window = 5\n",
    "        elif i == 1:\n",
    "            time_start = 5\n",
    "            time_end = 22\n",
    "            time_window = 17\n",
    "        elif i == 2:\n",
    "            time_start = 14\n",
    "            time_end = 17\n",
    "            time_window = 3\n",
    "        else:\n",
    "            time_start = 9\n",
    "            time_end = 11\n",
    "            time_window = 2\n",
    "\n",
    "        for j in range(len(cluster[i])):\n",
    "            orders, stops, weights, plts = sort_and_make_bin(cluster[i][j], veh_ton, veh_plt, veh_count)\n",
    "            bins, order, weight, plt, moving_time, working_time, out_time, in_time, bool = Bin_Slicing(orders, stops, weights, plts, time_window)\n",
    "            \n",
    "            for k in range(len(bins)):\n",
    "                row.append({'Stop_list':bins[k], 'Order_list':order[k],'weight':weight[k], 'plt':plt[k], 'moving_time':moving_time[k], 'working_time':working_time[k], 'out_time':out_time[k], 'in_time':in_time[k], 'time_cluster':i, 'time_start':time_start, 'time_end':time_end})\n",
    "    final_df = pd.DataFrame(row)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon1_bin_df = final_bin(mon_cluster_1, 1)\n",
    "mon3_bin_df = final_bin(mon_cluster_3, 3)\n",
    "mon11_bin_df = final_bin(mon_cluster_11, 11)\n",
    "\n",
    "tue1_bin_df = final_bin(tue_cluster_1, 1)\n",
    "tue3_bin_df = final_bin(tue_cluster_3, 3)\n",
    "tue11_bin_df = final_bin(tue_cluster_11, 11)\n",
    "\n",
    "wed1_bin_df = final_bin(wed_cluster_1, 1)\n",
    "wed3_bin_df = final_bin(wed_cluster_3, 3)\n",
    "wed11_bin_df = final_bin(wed_cluster_11, 11)\n",
    "\n",
    "thu1_bin_df = final_bin(thu_cluster_1, 1)\n",
    "thu3_bin_df = final_bin(thu_cluster_3, 3)\n",
    "thu11_bin_df = final_bin(thu_cluster_11, 11)\n",
    "\n",
    "fri1_bin_df = final_bin(fri_cluster_1, 1)\n",
    "fri3_bin_df = final_bin(fri_cluster_3, 3)\n",
    "fri11_bin_df = final_bin(fri_cluster_11, 11)\n",
    "\n",
    "sat1_bin_df = final_bin(sat_cluster_1, 1)\n",
    "sat3_bin_df = final_bin(sat_cluster_3, 3)\n",
    "sat11_bin_df = final_bin(sat_cluster_11, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stop_list</th>\n",
       "      <th>Order_list</th>\n",
       "      <th>weight</th>\n",
       "      <th>plt</th>\n",
       "      <th>moving_time</th>\n",
       "      <th>working_time</th>\n",
       "      <th>out_time</th>\n",
       "      <th>in_time</th>\n",
       "      <th>time_cluster</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[S_517, S_832]</td>\n",
       "      <td>[[O_302, O_1333, O_1334], [O_494, O_1173, O_11...</td>\n",
       "      <td>[3075.56, 422.8]</td>\n",
       "      <td>[5.11, 1.51]</td>\n",
       "      <td>3.006328</td>\n",
       "      <td>4.168328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[S_904, S_465, S_459, S_491]</td>\n",
       "      <td>[[O_541, O_1661, O_1662, O_1663], [O_273, O_81...</td>\n",
       "      <td>[2276.44, 724.8199999999999, 396.76, 87.06]</td>\n",
       "      <td>[3.59, 1.11, 0.8, 0.33]</td>\n",
       "      <td>3.053908</td>\n",
       "      <td>4.236908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[S_429, S_547]</td>\n",
       "      <td>[[O_255], [O_318, O_968, O_969]]</td>\n",
       "      <td>[1884.21, 1595.95]</td>\n",
       "      <td>[4.17, 2.98]</td>\n",
       "      <td>2.404127</td>\n",
       "      <td>4.019127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[S_519, S_430, S_440]</td>\n",
       "      <td>[[O_304, O_861, O_862], [O_256, O_930, O_931],...</td>\n",
       "      <td>[1839.72, 1364.53, 264.0]</td>\n",
       "      <td>[2.56, 1.99, 0.44]</td>\n",
       "      <td>3.031228</td>\n",
       "      <td>4.080228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[S_746, S_552, S_763]</td>\n",
       "      <td>[[O_444, O_1524, O_1525, O_1526, O_1527, O_152...</td>\n",
       "      <td>[1722.18, 1267.22, 231.7]</td>\n",
       "      <td>[2.83, 2.2600000000000002, 0.27]</td>\n",
       "      <td>3.169254</td>\n",
       "      <td>4.255254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>[S_268]</td>\n",
       "      <td>[[O_160, O_1284, O_1285, O_1286]]</td>\n",
       "      <td>[1335.31]</td>\n",
       "      <td>[2.01]</td>\n",
       "      <td>1.347498</td>\n",
       "      <td>1.598498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>[S_1055]</td>\n",
       "      <td>[[O_630, O_1287, O_1288]]</td>\n",
       "      <td>[1168.06]</td>\n",
       "      <td>[1.27]</td>\n",
       "      <td>0.237493</td>\n",
       "      <td>0.414493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>[S_982]</td>\n",
       "      <td>[[O_584, O_1664, O_1665, O_1666, O_1667]]</td>\n",
       "      <td>[1519.3]</td>\n",
       "      <td>[3.6900000000000004]</td>\n",
       "      <td>0.313225</td>\n",
       "      <td>1.132225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>[S_723]</td>\n",
       "      <td>[[O_430, O_766]]</td>\n",
       "      <td>[2943.2]</td>\n",
       "      <td>[2.9600000000000004]</td>\n",
       "      <td>1.193470</td>\n",
       "      <td>1.539470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>[S_576]</td>\n",
       "      <td>[[O_339, O_1466, O_1467, O_1468]]</td>\n",
       "      <td>[1006.73]</td>\n",
       "      <td>[2.04]</td>\n",
       "      <td>1.005394</td>\n",
       "      <td>1.259394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Stop_list  \\\n",
       "0                  [S_517, S_832]   \n",
       "1    [S_904, S_465, S_459, S_491]   \n",
       "2                  [S_429, S_547]   \n",
       "3           [S_519, S_430, S_440]   \n",
       "4           [S_746, S_552, S_763]   \n",
       "..                            ...   \n",
       "255                       [S_268]   \n",
       "256                      [S_1055]   \n",
       "257                       [S_982]   \n",
       "258                       [S_723]   \n",
       "259                       [S_576]   \n",
       "\n",
       "                                            Order_list  \\\n",
       "0    [[O_302, O_1333, O_1334], [O_494, O_1173, O_11...   \n",
       "1    [[O_541, O_1661, O_1662, O_1663], [O_273, O_81...   \n",
       "2                     [[O_255], [O_318, O_968, O_969]]   \n",
       "3    [[O_304, O_861, O_862], [O_256, O_930, O_931],...   \n",
       "4    [[O_444, O_1524, O_1525, O_1526, O_1527, O_152...   \n",
       "..                                                 ...   \n",
       "255                  [[O_160, O_1284, O_1285, O_1286]]   \n",
       "256                          [[O_630, O_1287, O_1288]]   \n",
       "257          [[O_584, O_1664, O_1665, O_1666, O_1667]]   \n",
       "258                                   [[O_430, O_766]]   \n",
       "259                  [[O_339, O_1466, O_1467, O_1468]]   \n",
       "\n",
       "                                          weight  \\\n",
       "0                               [3075.56, 422.8]   \n",
       "1    [2276.44, 724.8199999999999, 396.76, 87.06]   \n",
       "2                             [1884.21, 1595.95]   \n",
       "3                      [1839.72, 1364.53, 264.0]   \n",
       "4                      [1722.18, 1267.22, 231.7]   \n",
       "..                                           ...   \n",
       "255                                    [1335.31]   \n",
       "256                                    [1168.06]   \n",
       "257                                     [1519.3]   \n",
       "258                                     [2943.2]   \n",
       "259                                    [1006.73]   \n",
       "\n",
       "                                  plt  moving_time  working_time  out_time  \\\n",
       "0                        [5.11, 1.51]     3.006328      4.168328       0.0   \n",
       "1             [3.59, 1.11, 0.8, 0.33]     3.053908      4.236908       0.0   \n",
       "2                        [4.17, 2.98]     2.404127      4.019127       0.0   \n",
       "3                  [2.56, 1.99, 0.44]     3.031228      4.080228       0.0   \n",
       "4    [2.83, 2.2600000000000002, 0.27]     3.169254      4.255254       0.0   \n",
       "..                                ...          ...           ...       ...   \n",
       "255                            [2.01]     1.347498      1.598498       0.0   \n",
       "256                            [1.27]     0.237493      0.414493       0.0   \n",
       "257              [3.6900000000000004]     0.313225      1.132225       0.0   \n",
       "258              [2.9600000000000004]     1.193470      1.539470       0.0   \n",
       "259                            [2.04]     1.005394      1.259394       0.0   \n",
       "\n",
       "     in_time  time_cluster  time_start  time_end  \n",
       "0        0.0             0           5        10  \n",
       "1        0.0             0           5        10  \n",
       "2        0.0             0           5        10  \n",
       "3        0.0             0           5        10  \n",
       "4        0.0             0           5        10  \n",
       "..       ...           ...         ...       ...  \n",
       "255      0.0             3           9        11  \n",
       "256      0.0             3           9        11  \n",
       "257      0.0             3           9        11  \n",
       "258      0.0             3           9        11  \n",
       "259      0.0             3           9        11  \n",
       "\n",
       "[260 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon3_bin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin DataFrame의 weight와 plt를 합한 DataFrame 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reform_Bin(bin_df):\n",
    "    sum_weight = []\n",
    "    sum_plt = []\n",
    "    for i in range(len(bin_df)):\n",
    "        tmp_weight = sum(bin_df.loc[i, 'weight'])\n",
    "        sum_weight.append(tmp_weight)\n",
    "        tmp_plt = sum(bin_df.loc[i, 'plt'])\n",
    "        sum_plt.append(tmp_plt)\n",
    "\n",
    "    bin_df['weight'] = sum_weight\n",
    "    bin_df['plt'] = sum_plt\n",
    "    return bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mon1_bin_df = Reform_Bin(mon1_bin_df[:])\n",
    "new_mon3_bin_df = Reform_Bin(mon3_bin_df[:])\n",
    "new_mon11_bin_df = Reform_Bin(mon11_bin_df[:])\n",
    "\n",
    "new_tue1_bin_df = Reform_Bin(tue1_bin_df[:])\n",
    "new_tue3_bin_df = Reform_Bin(tue3_bin_df[:])\n",
    "new_tue11_bin_df = Reform_Bin(tue11_bin_df[:])\n",
    "\n",
    "new_wed1_bin_df = Reform_Bin(wed1_bin_df[:])\n",
    "new_wed3_bin_df = Reform_Bin(wed3_bin_df[:])\n",
    "new_wed11_bin_df = Reform_Bin(wed11_bin_df[:])\n",
    "\n",
    "new_thu1_bin_df = Reform_Bin(thu1_bin_df[:])\n",
    "new_thu3_bin_df = Reform_Bin(thu3_bin_df[:])\n",
    "new_thu11_bin_df = Reform_Bin(thu11_bin_df[:])\n",
    "\n",
    "new_fri1_bin_df = Reform_Bin(fri1_bin_df[:])\n",
    "new_fri3_bin_df = Reform_Bin(fri3_bin_df[:])\n",
    "new_fri11_bin_df = Reform_Bin(fri11_bin_df[:])\n",
    "\n",
    "new_sat1_bin_df = Reform_Bin(sat1_bin_df[:])\n",
    "new_sat3_bin_df = Reform_Bin(sat3_bin_df[:])\n",
    "new_sat11_bin_df = Reform_Bin(sat11_bin_df[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차량 배차 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vehicle_Dicision(df):\n",
    "    if df['weight'] <= 1000 and df['plt'] <= 2.8:\n",
    "        return 'one'\n",
    "    elif df['weight'] <= 2500 and df['plt'] <= 4:\n",
    "        return 'two'\n",
    "    elif df['weight'] <= 3500 and df['plt'] <= 8:\n",
    "        return 'three'\n",
    "    elif df['weight'] <= 5000 and df['plt'] <= 10:\n",
    "        return 'five'\n",
    "    elif df['weight'] <= 11000 and df['plt'] <= 16:\n",
    "        return 'eleven'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차량 배차를 위한 임시 데이터프레임\n",
    "tmp_veh1 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh2 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh3 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh5 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh11 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Assignment_Vehicle(bin_df, date):\n",
    "    global tmp_veh1, tmp_veh2, tmp_veh3, tmp_veh5, tmp_veh11\n",
    "    for i in range(len(bin_df)):\n",
    "        tmp_bin = bin_df.iloc[i]\n",
    "        veh_type = Vehicle_Dicision(tmp_bin)\n",
    "        \n",
    "        if veh_type == 'one':\n",
    "            tmp_veh = tmp_veh1\n",
    "        elif veh_type == 'two':\n",
    "            tmp_veh = tmp_veh2\n",
    "        elif veh_type == 'three':\n",
    "            tmp_veh = tmp_veh3\n",
    "        elif veh_type == 'five':\n",
    "            tmp_veh = tmp_veh5\n",
    "        elif veh_type == 'eleven':\n",
    "            tmp_veh = tmp_veh11\n",
    "\n",
    "        if len(tmp_veh) == 0:\n",
    "            out_time = tmp_bin['out_time']\n",
    "            out_time = (out_time // 1) * 60 + (out_time % 1) * 100\n",
    "            time_start = tmp_bin['time_start']\n",
    "            time_start = min_cal(time_start, -out_time, 0)\n",
    "            time_start = min_cal(time_start, -30, 0)\n",
    "            moving_time = tmp_bin['moving_time']\n",
    "            moving_time = (moving_time // 1) * 60 + (moving_time % 1) * 100\n",
    "            if time_start < 5:\n",
    "                time_start = 5\n",
    "                moving_time += 30\n",
    "            time_end = min_cal(time_start, moving_time, 0)\n",
    "            new_row = pd.DataFrame({'first_route': [tmp_bin['Stop_list']], 'first_order': [tmp_bin['Order_list']], 'first_start': [time_start], 'first_end': [time_end], 'first_plt': [tmp_bin['plt']], 'first_weight': [tmp_bin['weight']]})\n",
    "            tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            flag1 = False\n",
    "            in_time = tmp_bin['in_time']\n",
    "            in_time = (in_time // 1) * 60 + (in_time % 1) * 100\n",
    "            time_end = tmp_bin['time_end']\n",
    "            time_end = min_cal(time_end, in_time, 0)\n",
    "            moving_time = tmp_bin['moving_time']\n",
    "            moving_time = (moving_time // 1) * 60 + (moving_time % 1) * 100           \n",
    "            if time_end > 24:\n",
    "                time_end = 24\n",
    "            time_start = min_cal(time_end, -moving_time, 0)\n",
    "            time_start = min_cal(time_start, -30, 0)\n",
    "            for j in range(len(tmp_veh)):\n",
    "                if tmp_veh.iloc[j]['first_end'] < time_start and pd.isnull(tmp_veh.iloc[j]['second_start']):\n",
    "                    tmp_veh.at[j, 'second_route'] = tmp_bin['Stop_list']\n",
    "                    tmp_veh.at[j, 'second_order'] = tmp_bin['Order_list']\n",
    "                    tmp_veh.at[j, 'second_start'] = time_start\n",
    "                    tmp_veh.at[j, 'second_end'] = time_end   \n",
    "                    tmp_veh.at[j, 'second_plt'] = tmp_bin['plt']\n",
    "                    tmp_veh.at[j, 'second_weight'] = tmp_bin['weight']\n",
    "                    flag1 = True\n",
    "                    break\n",
    "\n",
    "            if not flag1:\n",
    "                flag2 = False\n",
    "                out_time = tmp_bin['out_time']\n",
    "                out_time = (out_time // 1) * 60 + (out_time % 1) * 100\n",
    "                time_start = tmp_bin['time_start']\n",
    "                time_start = min_cal(time_start, -out_time, 0)\n",
    "                time_start = min_cal(time_start, -30, 0)\n",
    "                \n",
    "                if time_start < 5:\n",
    "                    time_start = 5\n",
    "                time_end = min_cal(time_start, moving_time, 0)\n",
    "\n",
    "                for j in range(len(tmp_veh)):\n",
    "                    if tmp_veh.iloc[j]['first_start'] > time_end and pd.isnull(tmp_veh.iloc[j]['second_start']):\n",
    "                        tmp_veh.at[j, 'second_route'] = tmp_bin['Stop_list']\n",
    "                        tmp_veh.at[j, 'second_order'] = tmp_bin['Order_list']\n",
    "                        tmp_veh.at[j, 'second_start'] = time_start\n",
    "                        tmp_veh.at[j, 'second_end'] = time_end\n",
    "                        tmp_veh.at[j, 'second_plt'] = tmp_bin['plt']\n",
    "                        tmp_veh.at[j, 'second_weight'] = tmp_bin['weight']\n",
    "                        flag2 = True\n",
    "                        break\n",
    "                if not flag2:\n",
    "                    new_row = pd.DataFrame({'first_route': [tmp_bin['Stop_list']], 'first_order': [tmp_bin['Order_list']], 'first_start': [time_start], 'first_end': [time_end], 'first_plt': [tmp_bin['plt']], 'first_weight': [tmp_bin['weight']]})\n",
    "                    tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
    "\n",
    "        # tmp_veh 데이터프레임을 업데이트된 상태로 유지\n",
    "        if veh_type == 'one':\n",
    "            tmp_veh1 = tmp_veh\n",
    "        elif veh_type == 'two':\n",
    "            tmp_veh2 = tmp_veh\n",
    "        elif veh_type == 'three':\n",
    "            tmp_veh3 = tmp_veh\n",
    "        elif veh_type == 'five':\n",
    "            tmp_veh5 = tmp_veh\n",
    "        elif veh_type == 'eleven':\n",
    "            tmp_veh11 = tmp_veh\n",
    "    \n",
    "    for i in [tmp_veh1, tmp_veh2, tmp_veh3, tmp_veh5, tmp_veh11]:\n",
    "        date_row = [date]*len(i)\n",
    "        i['date'] = date_row\n",
    "    return tmp_veh1, tmp_veh2, tmp_veh3, tmp_veh5, tmp_veh11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "mon_veh1, mon_veh2, mon_veh3, mon_veh5, mon_veh11 = Assignment_Vehicle(new_mon1_bin_df, 1)\n",
    "mon_veh1, mon_veh2, mon_veh3, mon_veh5, mon_veh11 = Assignment_Vehicle(new_mon3_bin_df, 1)\n",
    "mon_veh1, mon_veh2, mon_veh3, mon_veh5, mon_veh11 = Assignment_Vehicle(new_mon11_bin_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차량 배차를 위한 임시 데이터프레임\n",
    "tmp_veh1 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh2 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh3 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh5 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh11 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "tue_veh1, tue_veh2, tue_veh3, tue_veh5, tue_veh11 = Assignment_Vehicle(new_tue1_bin_df, 2)\n",
    "tue_veh1, tue_veh2, tue_veh3, tue_veh5, tue_veh11 = Assignment_Vehicle(new_tue3_bin_df, 2)\n",
    "tue_veh1, tue_veh2, tue_veh3, tue_veh5, tue_veh11 = Assignment_Vehicle(new_tue11_bin_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차량 배차를 위한 임시 데이터프레임\n",
    "tmp_veh1 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh2 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh3 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh5 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh11 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "wed_veh1, wed_veh2, wed_veh3, wed_veh5, wed_veh11 = Assignment_Vehicle(new_wed1_bin_df, 3)\n",
    "wed_veh1, wed_veh2, wed_veh3, wed_veh5, wed_veh11 = Assignment_Vehicle(new_wed3_bin_df, 3)\n",
    "wed_veh1, wed_veh2, wed_veh3, wed_veh5, wed_veh11 = Assignment_Vehicle(new_wed11_bin_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차량 배차를 위한 임시 데이터프레임\n",
    "tmp_veh1 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh2 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh3 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh5 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh11 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "thu_veh1, thu_veh2, thu_veh3, thu_veh5, thu_veh11 = Assignment_Vehicle(new_thu1_bin_df, 4)\n",
    "thu_veh1, thu_veh2, thu_veh3, thu_veh5, thu_veh11 = Assignment_Vehicle(new_thu3_bin_df, 4)\n",
    "thu_veh1, thu_veh2, thu_veh3, thu_veh5, thu_veh11 = Assignment_Vehicle(new_thu11_bin_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차량 배차를 위한 임시 데이터프레임\n",
    "tmp_veh1 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh2 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh3 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh5 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh11 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "fri_veh1, fri_veh2, fri_veh3, fri_veh5, fri_veh11 = Assignment_Vehicle(new_fri1_bin_df, 5)\n",
    "fri_veh1, fri_veh2, fri_veh3, fri_veh5, fri_veh11 = Assignment_Vehicle(new_fri3_bin_df, 5)\n",
    "fri_veh1, fri_veh2, fri_veh3, fri_veh5, fri_veh11 = Assignment_Vehicle(new_fri11_bin_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차량 배차를 위한 임시 데이터프레임\n",
    "tmp_veh1 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh2 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh3 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh5 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])\n",
    "tmp_veh11 = pd.DataFrame(columns=['VehID', 'date', 'first_route', 'first_order', 'first_start', 'first_end', 'first_plt', 'first_weight', 'second_route', 'second_order', 'second_start', 'second_end', 'second_plt', 'second_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\180967973.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tmp_veh = pd.concat([tmp_veh, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "sat_veh1, sat_veh2, sat_veh3, sat_veh5, sat_veh11 = Assignment_Vehicle(new_fri1_bin_df, 6)\n",
    "sat_veh1, sat_veh2, sat_veh3, sat_veh5, sat_veh11 = Assignment_Vehicle(new_fri3_bin_df, 6)\n",
    "sat_veh1, sat_veh2, sat_veh3, sat_veh5, sat_veh11 = Assignment_Vehicle(new_fri11_bin_df, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh1_dfs = [mon_veh1, tue_veh1, wed_veh1, thu_veh1, fri_veh1, sat_veh1]\n",
    "veh2_dfs = [mon_veh2, tue_veh2, wed_veh2, thu_veh2, fri_veh2, sat_veh2]\n",
    "veh3_dfs = [mon_veh3, tue_veh3, wed_veh3, thu_veh3, fri_veh3, sat_veh3]\n",
    "veh5_dfs = [mon_veh5, tue_veh5, wed_veh5, thu_veh5, fri_veh5, sat_veh5]\n",
    "veh11_dfs = [mon_veh11, tue_veh11, wed_veh11, thu_veh11, fri_veh11, sat_veh11]\n",
    "\n",
    "veh1_df = pd.concat(veh1_dfs, ignore_index=True)\n",
    "veh2_df = pd.concat(veh2_dfs, ignore_index=True)\n",
    "veh3_df = pd.concat(veh3_dfs, ignore_index=True)\n",
    "veh5_df = pd.concat(veh5_dfs, ignore_index=True)\n",
    "veh11_df = pd.concat(veh11_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VehID</th>\n",
       "      <th>date</th>\n",
       "      <th>first_route</th>\n",
       "      <th>first_order</th>\n",
       "      <th>first_start</th>\n",
       "      <th>first_end</th>\n",
       "      <th>first_plt</th>\n",
       "      <th>first_weight</th>\n",
       "      <th>second_route</th>\n",
       "      <th>second_order</th>\n",
       "      <th>second_start</th>\n",
       "      <th>second_end</th>\n",
       "      <th>second_plt</th>\n",
       "      <th>second_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_986]</td>\n",
       "      <td>[[O_1354]]</td>\n",
       "      <td>5</td>\n",
       "      <td>7.123136</td>\n",
       "      <td>1.00</td>\n",
       "      <td>990.36</td>\n",
       "      <td>[S_986]</td>\n",
       "      <td>[[O_587]]</td>\n",
       "      <td>7.476864</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>70.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_575]</td>\n",
       "      <td>[[O_338, O_1115, O_1116, O_1117]]</td>\n",
       "      <td>5</td>\n",
       "      <td>5.499611</td>\n",
       "      <td>1.56</td>\n",
       "      <td>882.95</td>\n",
       "      <td>[S_372]</td>\n",
       "      <td>[[O_226, O_936, O_937, O_938]]</td>\n",
       "      <td>7.538073</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>723.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_614, S_844]</td>\n",
       "      <td>[[O_360, O_1148, O_1149, O_1150, O_1151], [O_5...</td>\n",
       "      <td>5</td>\n",
       "      <td>6.532411</td>\n",
       "      <td>2.20</td>\n",
       "      <td>937.31</td>\n",
       "      <td>[S_281]</td>\n",
       "      <td>[[O_171, O_1118]]</td>\n",
       "      <td>8.106178</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>947.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_871, S_676]</td>\n",
       "      <td>[[O_519, O_1473, O_1474, O_1475, O_1476, O_147...</td>\n",
       "      <td>5</td>\n",
       "      <td>8.492702</td>\n",
       "      <td>2.42</td>\n",
       "      <td>782.94</td>\n",
       "      <td>[S_658]</td>\n",
       "      <td>[[O_1393]]</td>\n",
       "      <td>19.488043</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>890.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_625]</td>\n",
       "      <td>[[O_1945, O_1949, O_1942]]</td>\n",
       "      <td>5</td>\n",
       "      <td>7.501970</td>\n",
       "      <td>2.04</td>\n",
       "      <td>990.94</td>\n",
       "      <td>[S_658]</td>\n",
       "      <td>[[O_1392, O_1394, O_394]]</td>\n",
       "      <td>19.488043</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>799.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_858, S_718]</td>\n",
       "      <td>[[O_725, O_1854], [O_608]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.581816</td>\n",
       "      <td>0.78</td>\n",
       "      <td>547.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_834]</td>\n",
       "      <td>[[O_2226, O_2227, O_2228]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.316432</td>\n",
       "      <td>2.07</td>\n",
       "      <td>951.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_830, S_579, S_777]</td>\n",
       "      <td>[[O_700], [O_490], [O_656, O_1180]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.486528</td>\n",
       "      <td>0.71</td>\n",
       "      <td>332.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_124]</td>\n",
       "      <td>[[O_101]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.575044</td>\n",
       "      <td>1.33</td>\n",
       "      <td>705.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_376]</td>\n",
       "      <td>[[O_318, O_2315, O_2316]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.132070</td>\n",
       "      <td>2.03</td>\n",
       "      <td>669.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    VehID  date            first_route  \\\n",
       "0     NaN     1                [S_986]   \n",
       "1     NaN     1                [S_575]   \n",
       "2     NaN     1         [S_614, S_844]   \n",
       "3     NaN     1         [S_871, S_676]   \n",
       "4     NaN     1                [S_625]   \n",
       "..    ...   ...                    ...   \n",
       "451   NaN     6         [S_858, S_718]   \n",
       "452   NaN     6                [S_834]   \n",
       "453   NaN     6  [S_830, S_579, S_777]   \n",
       "454   NaN     6                [S_124]   \n",
       "455   NaN     6                [S_376]   \n",
       "\n",
       "                                           first_order first_start  first_end  \\\n",
       "0                                           [[O_1354]]           5   7.123136   \n",
       "1                    [[O_338, O_1115, O_1116, O_1117]]           5   5.499611   \n",
       "2    [[O_360, O_1148, O_1149, O_1150, O_1151], [O_5...           5   6.532411   \n",
       "3    [[O_519, O_1473, O_1474, O_1475, O_1476, O_147...           5   8.492702   \n",
       "4                           [[O_1945, O_1949, O_1942]]           5   7.501970   \n",
       "..                                                 ...         ...        ...   \n",
       "451                         [[O_725, O_1854], [O_608]]        13.3  15.581816   \n",
       "452                         [[O_2226, O_2227, O_2228]]        13.3  15.316432   \n",
       "453                [[O_700], [O_490], [O_656, O_1180]]        13.3  15.486528   \n",
       "454                                          [[O_101]]        13.3  15.575044   \n",
       "455                          [[O_318, O_2315, O_2316]]        13.3  15.132070   \n",
       "\n",
       "     first_plt  first_weight second_route                    second_order  \\\n",
       "0         1.00        990.36      [S_986]                       [[O_587]]   \n",
       "1         1.56        882.95      [S_372]  [[O_226, O_936, O_937, O_938]]   \n",
       "2         2.20        937.31      [S_281]               [[O_171, O_1118]]   \n",
       "3         2.42        782.94      [S_658]                      [[O_1393]]   \n",
       "4         2.04        990.94      [S_658]       [[O_1392, O_1394, O_394]]   \n",
       "..         ...           ...          ...                             ...   \n",
       "451       0.78        547.12          NaN                             NaN   \n",
       "452       2.07        951.55          NaN                             NaN   \n",
       "453       0.71        332.80          NaN                             NaN   \n",
       "454       1.33        705.72          NaN                             NaN   \n",
       "455       2.03        669.34          NaN                             NaN   \n",
       "\n",
       "    second_start second_end second_plt second_weight  \n",
       "0       7.476864       10.0        0.3         70.49  \n",
       "1       7.538073       10.0       2.39        723.62  \n",
       "2       8.106178       10.0        1.8        947.97  \n",
       "3      19.488043       22.0        0.9        890.35  \n",
       "4      19.488043       22.0       1.81        799.35  \n",
       "..           ...        ...        ...           ...  \n",
       "451          NaN        NaN        NaN           NaN  \n",
       "452          NaN        NaN        NaN           NaN  \n",
       "453          NaN        NaN        NaN           NaN  \n",
       "454          NaN        NaN        NaN           NaN  \n",
       "455          NaN        NaN        NaN           NaN  \n",
       "\n",
       "[456 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veh1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차량 ID 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naming_ID(df, veh_kg):\n",
    "    ID_row = []\n",
    "    for i in range(len(df)):\n",
    "        ID_row.append(f\"Veh{veh_kg}_{i+1}\")\n",
    "    df['VehID'] = ID_row\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VehID</th>\n",
       "      <th>date</th>\n",
       "      <th>first_route</th>\n",
       "      <th>first_order</th>\n",
       "      <th>first_start</th>\n",
       "      <th>first_end</th>\n",
       "      <th>first_plt</th>\n",
       "      <th>first_weight</th>\n",
       "      <th>second_route</th>\n",
       "      <th>second_order</th>\n",
       "      <th>second_start</th>\n",
       "      <th>second_end</th>\n",
       "      <th>second_plt</th>\n",
       "      <th>second_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veh1000_1</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_986]</td>\n",
       "      <td>[[O_1354]]</td>\n",
       "      <td>5</td>\n",
       "      <td>7.123136</td>\n",
       "      <td>1.00</td>\n",
       "      <td>990.36</td>\n",
       "      <td>[S_986]</td>\n",
       "      <td>[[O_587]]</td>\n",
       "      <td>7.476864</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>70.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veh1000_2</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_575]</td>\n",
       "      <td>[[O_338, O_1115, O_1116, O_1117]]</td>\n",
       "      <td>5</td>\n",
       "      <td>5.499611</td>\n",
       "      <td>1.56</td>\n",
       "      <td>882.95</td>\n",
       "      <td>[S_372]</td>\n",
       "      <td>[[O_226, O_936, O_937, O_938]]</td>\n",
       "      <td>7.538073</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>723.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veh1000_3</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_614, S_844]</td>\n",
       "      <td>[[O_360, O_1148, O_1149, O_1150, O_1151], [O_5...</td>\n",
       "      <td>5</td>\n",
       "      <td>6.532411</td>\n",
       "      <td>2.20</td>\n",
       "      <td>937.31</td>\n",
       "      <td>[S_281]</td>\n",
       "      <td>[[O_171, O_1118]]</td>\n",
       "      <td>8.106178</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>947.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Veh1000_4</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_871, S_676]</td>\n",
       "      <td>[[O_519, O_1473, O_1474, O_1475, O_1476, O_147...</td>\n",
       "      <td>5</td>\n",
       "      <td>8.492702</td>\n",
       "      <td>2.42</td>\n",
       "      <td>782.94</td>\n",
       "      <td>[S_658]</td>\n",
       "      <td>[[O_1393]]</td>\n",
       "      <td>19.488043</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>890.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Veh1000_5</td>\n",
       "      <td>1</td>\n",
       "      <td>[S_625]</td>\n",
       "      <td>[[O_1945, O_1949, O_1942]]</td>\n",
       "      <td>5</td>\n",
       "      <td>7.501970</td>\n",
       "      <td>2.04</td>\n",
       "      <td>990.94</td>\n",
       "      <td>[S_658]</td>\n",
       "      <td>[[O_1392, O_1394, O_394]]</td>\n",
       "      <td>19.488043</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>799.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Veh1000_452</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_858, S_718]</td>\n",
       "      <td>[[O_725, O_1854], [O_608]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.581816</td>\n",
       "      <td>0.78</td>\n",
       "      <td>547.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Veh1000_453</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_834]</td>\n",
       "      <td>[[O_2226, O_2227, O_2228]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.316432</td>\n",
       "      <td>2.07</td>\n",
       "      <td>951.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Veh1000_454</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_830, S_579, S_777]</td>\n",
       "      <td>[[O_700], [O_490], [O_656, O_1180]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.486528</td>\n",
       "      <td>0.71</td>\n",
       "      <td>332.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Veh1000_455</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_124]</td>\n",
       "      <td>[[O_101]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.575044</td>\n",
       "      <td>1.33</td>\n",
       "      <td>705.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Veh1000_456</td>\n",
       "      <td>6</td>\n",
       "      <td>[S_376]</td>\n",
       "      <td>[[O_318, O_2315, O_2316]]</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15.132070</td>\n",
       "      <td>2.03</td>\n",
       "      <td>669.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           VehID  date            first_route  \\\n",
       "0      Veh1000_1     1                [S_986]   \n",
       "1      Veh1000_2     1                [S_575]   \n",
       "2      Veh1000_3     1         [S_614, S_844]   \n",
       "3      Veh1000_4     1         [S_871, S_676]   \n",
       "4      Veh1000_5     1                [S_625]   \n",
       "..           ...   ...                    ...   \n",
       "451  Veh1000_452     6         [S_858, S_718]   \n",
       "452  Veh1000_453     6                [S_834]   \n",
       "453  Veh1000_454     6  [S_830, S_579, S_777]   \n",
       "454  Veh1000_455     6                [S_124]   \n",
       "455  Veh1000_456     6                [S_376]   \n",
       "\n",
       "                                           first_order first_start  first_end  \\\n",
       "0                                           [[O_1354]]           5   7.123136   \n",
       "1                    [[O_338, O_1115, O_1116, O_1117]]           5   5.499611   \n",
       "2    [[O_360, O_1148, O_1149, O_1150, O_1151], [O_5...           5   6.532411   \n",
       "3    [[O_519, O_1473, O_1474, O_1475, O_1476, O_147...           5   8.492702   \n",
       "4                           [[O_1945, O_1949, O_1942]]           5   7.501970   \n",
       "..                                                 ...         ...        ...   \n",
       "451                         [[O_725, O_1854], [O_608]]        13.3  15.581816   \n",
       "452                         [[O_2226, O_2227, O_2228]]        13.3  15.316432   \n",
       "453                [[O_700], [O_490], [O_656, O_1180]]        13.3  15.486528   \n",
       "454                                          [[O_101]]        13.3  15.575044   \n",
       "455                          [[O_318, O_2315, O_2316]]        13.3  15.132070   \n",
       "\n",
       "     first_plt  first_weight second_route                    second_order  \\\n",
       "0         1.00        990.36      [S_986]                       [[O_587]]   \n",
       "1         1.56        882.95      [S_372]  [[O_226, O_936, O_937, O_938]]   \n",
       "2         2.20        937.31      [S_281]               [[O_171, O_1118]]   \n",
       "3         2.42        782.94      [S_658]                      [[O_1393]]   \n",
       "4         2.04        990.94      [S_658]       [[O_1392, O_1394, O_394]]   \n",
       "..         ...           ...          ...                             ...   \n",
       "451       0.78        547.12          NaN                             NaN   \n",
       "452       2.07        951.55          NaN                             NaN   \n",
       "453       0.71        332.80          NaN                             NaN   \n",
       "454       1.33        705.72          NaN                             NaN   \n",
       "455       2.03        669.34          NaN                             NaN   \n",
       "\n",
       "    second_start second_end second_plt second_weight  \n",
       "0       7.476864       10.0        0.3         70.49  \n",
       "1       7.538073       10.0       2.39        723.62  \n",
       "2       8.106178       10.0        1.8        947.97  \n",
       "3      19.488043       22.0        0.9        890.35  \n",
       "4      19.488043       22.0       1.81        799.35  \n",
       "..           ...        ...        ...           ...  \n",
       "451          NaN        NaN        NaN           NaN  \n",
       "452          NaN        NaN        NaN           NaN  \n",
       "453          NaN        NaN        NaN           NaN  \n",
       "454          NaN        NaN        NaN           NaN  \n",
       "455          NaN        NaN        NaN           NaN  \n",
       "\n",
       "[456 rows x 14 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veh1_df = Naming_ID(veh1_df, 1000)\n",
    "veh2_df = Naming_ID(veh2_df, 2500)\n",
    "veh3_df = Naming_ID(veh3_df, 3500)\n",
    "veh4_df = Naming_ID(veh5_df, 5000)\n",
    "veh5_df = Naming_ID(veh11_df, 11000)\n",
    "veh1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle1_info = pd.DataFrame(columns=['VehicleID', 'Round', 'OrderCount', 'StopCount', 'Plt', 'TravelDistance', 'WorkTime', 'TravelTime','UnloadingTime','WaitingTime','TotalCost','FixedCost','VariableCost'])\n",
    "vehicle2_info = pd.DataFrame(columns=['VehicleID', 'Round', 'OrderCount', 'StopCount', 'Plt', 'TravelDistance', 'WorkTime', 'TravelTime','UnloadingTime','WaitingTime','TotalCost','FixedCost','VariableCost'])\n",
    "vehicle3_info = pd.DataFrame(columns=['VehicleID', 'Round', 'OrderCount', 'StopCount', 'Plt', 'TravelDistance', 'WorkTime', 'TravelTime','UnloadingTime','WaitingTime','TotalCost','FixedCost','VariableCost'])\n",
    "vehicle5_info = pd.DataFrame(columns=['VehicleID', 'Round', 'OrderCount', 'StopCount', 'Plt', 'TravelDistance', 'WorkTime', 'TravelTime','UnloadingTime','WaitingTime','TotalCost','FixedCost','VariableCost'])\n",
    "vehicle11_info = pd.DataFrame(columns=['VehicleID', 'Round', 'OrderCount', 'StopCount', 'Plt', 'TravelDistance', 'WorkTime', 'TravelTime','UnloadingTime','WaitingTime','TotalCost','FixedCost','VariableCost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차량 결과 테이블 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_vehicle(veh_df, veh_info, fixed_cost, variable_cost):\n",
    "    for i in range(len(veh_df)):\n",
    "        tmp = veh_df.iloc[i]\n",
    "        flag = pd.isnull(tmp['second_plt'])\n",
    "        \n",
    "        if flag:\n",
    "            od_distance, od_time = OD_Matrix(tmp['first_route'])\n",
    "            mt, wt, ot, it = moving_time(tmp['first_route'], od_time)\n",
    "            working_time = (mt // 1) * 60 + (mt % 1) * 100\n",
    "            working_time = working_time + 5 * len(tmp['first_route']) + 10 * tmp['first_plt']\n",
    "            info_row = pd.DataFrame({\n",
    "                'VehicleID': [tmp['VehID']],\n",
    "                'Round': [1],\n",
    "                'OrderCount': [len(tmp['first_order'])],\n",
    "                'StopCount': [len(tmp['first_route'])],\n",
    "                'Plt': [tmp['first_plt']],\n",
    "                'TravelDistance': [route_distance(tmp['first_route'], od_distance)],\n",
    "                'WorkTime': [working_time],\n",
    "                'TravelTime': [(mt // 1) * 60 + (mt % 1) * 100],\n",
    "                'UnloadingTime': [5 * len(tmp['first_route']) + 10 * tmp['first_plt']],\n",
    "                'WaitingTime': [0],\n",
    "                'TotalCost': [fixed_cost + (route_distance(tmp['first_route'], od_distance)) * variable_cost],\n",
    "                'FixedCost': [fixed_cost],\n",
    "                'VariableCost': [(route_distance(tmp['first_route'], od_distance)) * variable_cost]\n",
    "            })\n",
    "            veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            if tmp['first_start'] < tmp['second_start']:\n",
    "                # First route\n",
    "                od_distance, od_time = OD_Matrix(tmp['first_route'])\n",
    "                mt, wt, ot, it = moving_time(tmp['first_route'], od_time)\n",
    "                working_time = (mt // 1) * 60 + (mt % 1) * 100\n",
    "                working_time = working_time + 5 * len(tmp['first_route']) + 10 * tmp['first_plt']\n",
    "                info_row = pd.DataFrame({\n",
    "                    'VehicleID': [tmp['VehID']],\n",
    "                    'Round': [1],\n",
    "                    'OrderCount': [len(tmp['first_order'])],\n",
    "                    'StopCount': [len(tmp['first_route'])],\n",
    "                    'Plt': [tmp['first_plt']],\n",
    "                    'TravelDistance': [route_distance(tmp['first_route'], od_distance)],\n",
    "                    'WorkTime': [working_time],\n",
    "                    'TravelTime': [(mt // 1) * 60 + (mt % 1) * 100],\n",
    "                    'UnloadingTime': [5 * len(tmp['first_route']) + 10 * tmp['first_plt']],\n",
    "                    'WaitingTime': [0],\n",
    "                    'TotalCost': [fixed_cost + (route_distance(tmp['first_route'], od_distance)) * variable_cost],\n",
    "                    'FixedCost': [fixed_cost],\n",
    "                    'VariableCost': [(route_distance(tmp['first_route'], od_distance)) * variable_cost]\n",
    "                })\n",
    "                veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n",
    "\n",
    "                # Second route\n",
    "                od_distance, od_time = OD_Matrix(tmp['second_route'])\n",
    "                mt, wt, ot, it = moving_time(tmp['second_route'], od_time)\n",
    "                working_time = (mt // 1) * 60 + (mt % 1) * 100\n",
    "                working_time = working_time + 5 * len(tmp['second_route']) + 10 * tmp['second_plt']\n",
    "                info_row = pd.DataFrame({\n",
    "                    'VehicleID': [tmp['VehID']],\n",
    "                    'Round': [2],\n",
    "                    'OrderCount': [len(tmp['second_order'])],\n",
    "                    'StopCount': [len(tmp['second_route'])],\n",
    "                    'Plt': [tmp['second_plt']],\n",
    "                    'TravelDistance': [route_distance(tmp['second_route'], od_distance)],\n",
    "                    'WorkTime': [working_time],\n",
    "                    'TravelTime': [(mt // 1) * 60 + (mt % 1) * 100],\n",
    "                    'UnloadingTime': [5 * len(tmp['second_route']) + 10 * tmp['second_plt']],\n",
    "                    'WaitingTime': [0],\n",
    "                    'TotalCost': [fixed_cost + (route_distance(tmp['second_route'], od_distance)) * variable_cost],\n",
    "                    'FixedCost': [fixed_cost],\n",
    "                    'VariableCost': [(route_distance(tmp['second_route'], od_distance)) * variable_cost]\n",
    "                })\n",
    "                veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                # Fisrt route\n",
    "                od_distance, od_time = OD_Matrix(tmp['second_route'])\n",
    "                mt, wt, ot, it = moving_time(tmp['second_route'], od_time)\n",
    "                working_time = (mt // 1) * 60 + (mt % 1) * 100\n",
    "                working_time = working_time + 5 * len(tmp['second_route']) + 10 * tmp['second_plt']\n",
    "                info_row = pd.DataFrame({\n",
    "                    'VehicleID': [tmp['VehID']],\n",
    "                    'Round': [1],\n",
    "                    'OrderCount': [len(tmp['second_order'])],\n",
    "                    'StopCount': [len(tmp['second_route'])],\n",
    "                    'Plt': [tmp['second_plt']],\n",
    "                    'TravelDistance': [route_distance(tmp['second_route'], od_distance)],\n",
    "                    'WorkTime': [working_time],\n",
    "                    'TravelTime': [(mt // 1) * 60 + (mt % 1) * 100],\n",
    "                    'UnloadingTime': [5 * len(tmp['second_route']) + 10 * tmp['second_plt']],\n",
    "                    'WaitingTime': [0],\n",
    "                    'TotalCost': [fixed_cost + (route_distance(tmp['second_route'], od_distance)) * variable_cost],\n",
    "                    'FixedCost': [fixed_cost],\n",
    "                    'VariableCost': [(route_distance(tmp['second_route'], od_distance)) * variable_cost]\n",
    "                })\n",
    "                veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n",
    "\n",
    "                # Second Route\n",
    "                od_distance, od_time = OD_Matrix(tmp['first_route'])\n",
    "                mt, wt, ot, it = moving_time(tmp['first_route'], od_time)\n",
    "                working_time = (mt // 1) * 60 + (mt % 1) * 100\n",
    "                working_time = working_time + 5 * len(tmp['first_route']) + 10 * tmp['first_plt']\n",
    "                info_row = pd.DataFrame({\n",
    "                    'VehicleID': [tmp['VehID']],\n",
    "                    'Round': [2],\n",
    "                    'OrderCount': [len(tmp['first_order'])],\n",
    "                    'StopCount': [len(tmp['first_route'])],\n",
    "                    'Plt': [tmp['first_plt']],\n",
    "                    'TravelDistance': [route_distance(tmp['first_route'], od_distance)],\n",
    "                    'WorkTime': [working_time],\n",
    "                    'TravelTime': [(mt // 1) * 60 + (mt % 1) * 100],\n",
    "                    'UnloadingTime': [5 * len(tmp['first_route']) + 10 * tmp['first_plt']],\n",
    "                    'WaitingTime': [0],\n",
    "                    'TotalCost': [fixed_cost + (route_distance(tmp['first_route'], od_distance)) * variable_cost],\n",
    "                    'FixedCost': [fixed_cost],\n",
    "                    'VariableCost': [(route_distance(tmp['first_route'], od_distance)) * variable_cost]\n",
    "                })\n",
    "                veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n",
    "    return veh_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\2636133458.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\2636133458.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\2636133458.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\2636133458.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\2636133458.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  veh_info = pd.concat([veh_info, info_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "vehicle1_result = result_vehicle(veh1_df, vehicle1_info, 145400, 173)\n",
    "vehicle2_result = result_vehicle(veh2_df, vehicle1_info, 173200, 173)\n",
    "vehicle3_result = result_vehicle(veh3_df, vehicle1_info, 200000, 237)\n",
    "vehicle5_result = result_vehicle(veh5_df, vehicle1_info, 234000, 355)\n",
    "vehicle11_result = result_vehicle(veh11_df, vehicle1_info, 185200, 421)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VehicleID</th>\n",
       "      <th>Round</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>StopCount</th>\n",
       "      <th>Plt</th>\n",
       "      <th>TravelDistance</th>\n",
       "      <th>WorkTime</th>\n",
       "      <th>TravelTime</th>\n",
       "      <th>UnloadingTime</th>\n",
       "      <th>WaitingTime</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>FixedCost</th>\n",
       "      <th>VariableCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veh1000_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>70.275041</td>\n",
       "      <td>117.313576</td>\n",
       "      <td>102.313576</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>157557.582166</td>\n",
       "      <td>145400</td>\n",
       "      <td>12157.582166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veh1000_1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>70.275041</td>\n",
       "      <td>110.313576</td>\n",
       "      <td>102.313576</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>157557.582166</td>\n",
       "      <td>145400</td>\n",
       "      <td>12157.582166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veh1000_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.56</td>\n",
       "      <td>21.950981</td>\n",
       "      <td>70.561117</td>\n",
       "      <td>49.961117</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "      <td>149197.519778</td>\n",
       "      <td>145400</td>\n",
       "      <td>3797.519778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Veh1000_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.39</td>\n",
       "      <td>51.822795</td>\n",
       "      <td>125.092726</td>\n",
       "      <td>96.192726</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0</td>\n",
       "      <td>154365.343565</td>\n",
       "      <td>145400</td>\n",
       "      <td>8965.343565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Veh1000_3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.20</td>\n",
       "      <td>56.053911</td>\n",
       "      <td>145.241094</td>\n",
       "      <td>113.241094</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>155097.326663</td>\n",
       "      <td>145400</td>\n",
       "      <td>9697.326663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>Veh11000_102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.23</td>\n",
       "      <td>30.442602</td>\n",
       "      <td>206.827420</td>\n",
       "      <td>49.527420</td>\n",
       "      <td>157.3</td>\n",
       "      <td>0</td>\n",
       "      <td>198016.335565</td>\n",
       "      <td>185200</td>\n",
       "      <td>12816.335565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>Veh11000_102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14.67</td>\n",
       "      <td>199.226802</td>\n",
       "      <td>390.756824</td>\n",
       "      <td>234.056824</td>\n",
       "      <td>156.7</td>\n",
       "      <td>0</td>\n",
       "      <td>269074.483590</td>\n",
       "      <td>185200</td>\n",
       "      <td>83874.483590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Veh11000_103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11.21</td>\n",
       "      <td>171.226664</td>\n",
       "      <td>336.854005</td>\n",
       "      <td>214.754005</td>\n",
       "      <td>122.1</td>\n",
       "      <td>0</td>\n",
       "      <td>257286.425340</td>\n",
       "      <td>185200</td>\n",
       "      <td>72086.425340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>Veh11000_103</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.13</td>\n",
       "      <td>28.133131</td>\n",
       "      <td>146.384417</td>\n",
       "      <td>50.084417</td>\n",
       "      <td>96.3</td>\n",
       "      <td>0</td>\n",
       "      <td>197044.047993</td>\n",
       "      <td>185200</td>\n",
       "      <td>11844.047993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>Veh11000_104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.31</td>\n",
       "      <td>21.882922</td>\n",
       "      <td>167.376117</td>\n",
       "      <td>49.276117</td>\n",
       "      <td>118.1</td>\n",
       "      <td>0</td>\n",
       "      <td>194412.710304</td>\n",
       "      <td>185200</td>\n",
       "      <td>9212.710304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2747 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VehicleID Round OrderCount StopCount    Plt  TravelDistance  \\\n",
       "0        Veh1000_1     1          1         1   1.00       70.275041   \n",
       "1        Veh1000_1     2          1         1   0.30       70.275041   \n",
       "2        Veh1000_2     1          1         1   1.56       21.950981   \n",
       "3        Veh1000_2     2          1         1   2.39       51.822795   \n",
       "4        Veh1000_3     1          2         2   2.20       56.053911   \n",
       "...            ...   ...        ...       ...    ...             ...   \n",
       "2742  Veh11000_102     1          1         1  15.23       30.442602   \n",
       "2743  Veh11000_102     2          2         2  14.67      199.226802   \n",
       "2744  Veh11000_103     1          2         2  11.21      171.226664   \n",
       "2745  Veh11000_103     2          1         1   9.13       28.133131   \n",
       "2746  Veh11000_104     1          1         1  11.31       21.882922   \n",
       "\n",
       "        WorkTime  TravelTime  UnloadingTime WaitingTime      TotalCost  \\\n",
       "0     117.313576  102.313576           15.0           0  157557.582166   \n",
       "1     110.313576  102.313576            8.0           0  157557.582166   \n",
       "2      70.561117   49.961117           20.6           0  149197.519778   \n",
       "3     125.092726   96.192726           28.9           0  154365.343565   \n",
       "4     145.241094  113.241094           32.0           0  155097.326663   \n",
       "...          ...         ...            ...         ...            ...   \n",
       "2742  206.827420   49.527420          157.3           0  198016.335565   \n",
       "2743  390.756824  234.056824          156.7           0  269074.483590   \n",
       "2744  336.854005  214.754005          122.1           0  257286.425340   \n",
       "2745  146.384417   50.084417           96.3           0  197044.047993   \n",
       "2746  167.376117   49.276117          118.1           0  194412.710304   \n",
       "\n",
       "     FixedCost  VariableCost  \n",
       "0       145400  12157.582166  \n",
       "1       145400  12157.582166  \n",
       "2       145400   3797.519778  \n",
       "3       145400   8965.343565  \n",
       "4       145400   9697.326663  \n",
       "...        ...           ...  \n",
       "2742    185200  12816.335565  \n",
       "2743    185200  83874.483590  \n",
       "2744    185200  72086.425340  \n",
       "2745    185200  11844.047993  \n",
       "2746    185200   9212.710304  \n",
       "\n",
       "[2747 rows x 13 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_result_dfs = [vehicle1_result, vehicle2_result, vehicle3_result, vehicle5_result, vehicle11_result]\n",
    "vehicle_result = pd.concat(vehicle_result_dfs, ignore_index=True)\n",
    "\n",
    "vehicle_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_result.to_csv('차량 결과 테이블.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh1_order_info = pd.DataFrame(columns=['Order_ID', 'VehicleID', 'Sequence', 'Stop_ID', 'ArrivalTime', 'WaitingTime', 'UnloadingTime', 'DeaprtureTime'])\n",
    "veh2_order_info = pd.DataFrame(columns=['Order_ID', 'VehicleID', 'Sequence', 'Stop_ID', 'ArrivalTime', 'WaitingTime', 'UnloadingTime', 'DeaprtureTime'])\n",
    "veh3_order_info = pd.DataFrame(columns=['Order_ID', 'VehicleID', 'Sequence', 'Stop_ID', 'ArrivalTime', 'WaitingTime', 'UnloadingTime', 'DeaprtureTime'])\n",
    "veh5_order_info = pd.DataFrame(columns=['Order_ID', 'VehicleID', 'Sequence', 'Stop_ID', 'ArrivalTime', 'WaitingTime', 'UnloadingTime', 'DeaprtureTime'])\n",
    "veh11_order_info = pd.DataFrame(columns=['Order_ID', 'VehicleID', 'Sequence', 'Stop_ID', 'ArrivalTime', 'WaitingTime', 'UnloadingTime', 'DeaprtureTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def int_to_date(int_value, start_date='2024/09/'):\n",
    "# #     date = '0' + str(int_value)\n",
    "# #     ret_date = start_date + date\n",
    "# #     return ret_date\n",
    "# # kk = int_to_date(1)\n",
    "\n",
    "# def date_time(int_value, str_value, start_date ='2024/09/'):\n",
    "#     date = '0' + str(int_value)\n",
    "#     ret_date = start_date + date\n",
    "\n",
    "#     str_value = round(float(str_value), 2)\n",
    "#     str_value = \"{:.2f}\".format(str_value)\n",
    "\n",
    "#     time = str_value.replace('.', '/')\n",
    "#     date_time = ret_date + \"/\" + time\n",
    "\n",
    "#     return date_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def result_order(veh_df, order_info):\n",
    "#     def calculate_unloading_time(order_id, day):\n",
    "#         if day == 1:\n",
    "#             df = order_mon_df\n",
    "#         elif day == 2:\n",
    "#             df = order_tue_df\n",
    "#         elif day == 3:\n",
    "#             df = order_wed_df\n",
    "#         elif day == 4:\n",
    "#             df = order_thu_df\n",
    "#         elif day == 5:\n",
    "#             df = order_fri_df\n",
    "#         else:\n",
    "#             df = order_sat_df\n",
    "        \n",
    "#         # 주문 ID가 데이터프레임에 있는지 확인\n",
    "#         if order_id in df['Order_ID'].values:\n",
    "#             return df[df['Order_ID'] == order_id]['plt'].values[0] * 10 + 5\n",
    "#         else:\n",
    "#             return 0  # 기본값을 0으로 설정 (또는 원하는 다른 값으로 설정)\n",
    "\n",
    "#     def process_route(route, orders, start_time, sequence_offset=0):\n",
    "#         nonlocal order_info  # nonlocal 키워드를 사용하여 외부 변수 참조\n",
    "#         od_distance, od_time = OD_Matrix(route)\n",
    "#         for j in range(len(route)):\n",
    "#             moving_time = sum(od_time[route[m]][route[m+1]] for m in range(j))\n",
    "#             arrival_time = min_cal(start_time, 30, 0)\n",
    "#             arrival_time = min_cal(arrival_time, moving_time, 0)\n",
    "#             for k in range(len(orders[j])):\n",
    "#                 unloading_time = calculate_unloading_time(orders[j][k], tmp['date'])\n",
    "#                 sequence = sequence_offset + j * len(orders[j]) + k + 1\n",
    "#                 info_row = pd.DataFrame({\n",
    "#                     'Order_ID': [orders[j][k]],\n",
    "#                     'VehicleID': [tmp['VehID']],\n",
    "#                     'Sequence': [sequence],\n",
    "#                     'StopID': [route[j]],\n",
    "#                     'ArrivalTime': [date_time(tmp['date'], [arrival_time])],\n",
    "#                     'WaitingTime': [0],\n",
    "#                     'UnloadingTime': [unloading_time],\n",
    "#                     'DepartureTime': [date_time(tmp['date'],min_cal(arrival_time, unloading_time, 0))]\n",
    "#                 })\n",
    "#                 order_info = pd.concat([order_info, info_row], ignore_index=True)\n",
    "#         return order_info\n",
    "\n",
    "#     for i in range(len(veh_df)):\n",
    "#         tmp = veh_df.iloc[i]\n",
    "#         flag = pd.isnull(tmp['second_plt'])\n",
    "        \n",
    "#         if flag:\n",
    "#             order_info = process_route(tmp['first_route'], tmp['first_order'], tmp['first_start'])\n",
    "#         else:\n",
    "#             if tmp['first_start'] < tmp['second_start']:\n",
    "#                 order_info = process_route(tmp['first_route'], tmp['first_order'], tmp['first_start'])\n",
    "#                 cnt = sum(len(o) for o in tmp['first_order'])\n",
    "#                 order_info = process_route(tmp['second_route'], tmp['second_order'], tmp['second_start'], sequence_offset=cnt)\n",
    "#             else:\n",
    "#                 order_info = process_route(tmp['second_route'], tmp['second_order'], tmp['second_start'])\n",
    "#                 cnt = sum(len(o) for o in tmp['second_order'])\n",
    "#                 order_info = process_route(tmp['first_route'], tmp['first_order'], tmp['first_start'], sequence_offset=cnt)\n",
    "\n",
    "#     return order_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(int_value, str_value, start_date='2024/09/'):\n",
    "    date = '0' + str(int_value)\n",
    "    ret_date = start_date + date\n",
    "\n",
    "    # str_value를 소수점 두 번째 자리까지 반올림하고 문자열로 변환\n",
    "    str_value = round(float(str_value), 2)\n",
    "    str_value = \"{:.2f}\".format(str_value)\n",
    "\n",
    "    time = str_value.replace('.', '/')\n",
    "    date_time = ret_date + \"/\" + time\n",
    "\n",
    "    return date_time\n",
    "\n",
    "def result_order(veh_df, order_info):\n",
    "    def calculate_unloading_time(order_id, day):\n",
    "        if day == 1:\n",
    "            df = order_mon_df\n",
    "        elif day == 2:\n",
    "            df = order_tue_df\n",
    "        elif day == 3:\n",
    "            df = order_wed_df\n",
    "        elif day == 4:\n",
    "            df = order_thu_df\n",
    "        elif day == 5:\n",
    "            df = order_fri_df\n",
    "        else:\n",
    "            df = order_sat_df\n",
    "        \n",
    "        # 주문 ID가 데이터프레임에 있는지 확인\n",
    "        if order_id in df['Order_ID'].values:\n",
    "            return df[df['Order_ID'] == order_id]['plt'].values[0] * 10 + 5\n",
    "        else:\n",
    "            return 0  # 기본값을 0으로 설정 (또는 원하는 다른 값으로 설정)\n",
    "\n",
    "    def process_route(route, orders, start_time, sequence_offset=0):\n",
    "        nonlocal order_info  # nonlocal 키워드를 사용하여 외부 변수 참조\n",
    "        od_distance, od_time = OD_Matrix(route)\n",
    "        for j in range(len(route)):\n",
    "            moving_time = sum(od_time[route[m]][route[m+1]] for m in range(j))\n",
    "            arrival_time = min_cal(start_time, 30, 0)\n",
    "            arrival_time = min_cal(arrival_time, moving_time, 0)\n",
    "            for k in range(len(orders[j])):\n",
    "                unloading_time = calculate_unloading_time(orders[j][k], tmp['date'])\n",
    "                sequence = sequence_offset + j * len(orders[j]) + k + 1\n",
    "                info_row = pd.DataFrame({\n",
    "                    'Order_ID': [orders[j][k]],\n",
    "                    'VehicleID': [tmp['VehID']],\n",
    "                    'Sequence': [sequence],\n",
    "                    'StopID': [route[j]],\n",
    "                    'ArrivalTime': [date_time(tmp['date'], arrival_time)],\n",
    "                    'WaitingTime': [0],\n",
    "                    'UnloadingTime': [unloading_time],\n",
    "                    'DepartureTime': [date_time(tmp['date'], min_cal(arrival_time, unloading_time, 0))]\n",
    "                })\n",
    "                order_info = pd.concat([order_info, info_row], ignore_index=True)\n",
    "        return order_info\n",
    "\n",
    "    for i in range(len(veh_df)):\n",
    "        tmp = veh_df.iloc[i]\n",
    "        flag = pd.isnull(tmp['second_plt'])\n",
    "        \n",
    "        if flag:\n",
    "            order_info = process_route(tmp['first_route'], tmp['first_order'], tmp['first_start'])\n",
    "        else:\n",
    "            if tmp['first_start'] < tmp['second_start']:\n",
    "                order_info = process_route(tmp['first_route'], tmp['first_order'], tmp['first_start'])\n",
    "                cnt = sum(len(o) for o in tmp['first_order'])\n",
    "                order_info = process_route(tmp['second_route'], tmp['second_order'], tmp['second_start'], sequence_offset=cnt)\n",
    "            else:\n",
    "                order_info = process_route(tmp['second_route'], tmp['second_order'], tmp['second_start'])\n",
    "                cnt = sum(len(o) for o in tmp['second_order'])\n",
    "                order_info = process_route(tmp['first_route'], tmp['first_order'], tmp['first_start'], sequence_offset=cnt)\n",
    "\n",
    "    return order_info\n",
    "\n",
    "# wlvlxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\526353482.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  order_info = pd.concat([order_info, info_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\526353482.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  order_info = pd.concat([order_info, info_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\526353482.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  order_info = pd.concat([order_info, info_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\526353482.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  order_info = pd.concat([order_info, info_row], ignore_index=True)\n",
      "C:\\Users\\정호준\\AppData\\Local\\Temp\\ipykernel_13824\\526353482.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  order_info = pd.concat([order_info, info_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "order1_result = result_order(veh1_df, veh1_order_info)\n",
    "order2_result = result_order(veh2_df, veh2_order_info)\n",
    "order3_result = result_order(veh3_df, veh3_order_info)\n",
    "order5_result = result_order(veh5_df, veh5_order_info)\n",
    "order11_result = result_order(veh11_df, veh11_order_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>VehicleID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Stop_ID</th>\n",
       "      <th>ArrivalTime</th>\n",
       "      <th>WaitingTime</th>\n",
       "      <th>UnloadingTime</th>\n",
       "      <th>DeaprtureTime</th>\n",
       "      <th>StopID</th>\n",
       "      <th>DepartureTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O_1354</td>\n",
       "      <td>Veh1000_1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/01/5/30</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_986</td>\n",
       "      <td>2024/09/01/5/45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O_587</td>\n",
       "      <td>Veh1000_1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/01/8/18</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_986</td>\n",
       "      <td>2024/09/01/8/26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O_338</td>\n",
       "      <td>Veh1000_2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/01/5/30</td>\n",
       "      <td>0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_575</td>\n",
       "      <td>2024/09/01/5/41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O_1115</td>\n",
       "      <td>Veh1000_2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/01/5/30</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_575</td>\n",
       "      <td>2024/09/01/5/38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O_1116</td>\n",
       "      <td>Veh1000_2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/01/5/30</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_575</td>\n",
       "      <td>2024/09/01/5/37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12357</th>\n",
       "      <td>O_1328</td>\n",
       "      <td>Veh11000_102</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/06/19/28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_712</td>\n",
       "      <td>2024/09/06/19/28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12358</th>\n",
       "      <td>O_2122</td>\n",
       "      <td>Veh11000_103</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/06/5/30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_1082</td>\n",
       "      <td>2024/09/06/5/30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12359</th>\n",
       "      <td>O_2328</td>\n",
       "      <td>Veh11000_103</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/06/6/29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_994</td>\n",
       "      <td>2024/09/06/6/29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12360</th>\n",
       "      <td>O_2046</td>\n",
       "      <td>Veh11000_103</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/06/16/10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_610</td>\n",
       "      <td>2024/09/06/16/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12361</th>\n",
       "      <td>O_497</td>\n",
       "      <td>Veh11000_104</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024/09/06/14/00</td>\n",
       "      <td>0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S_587</td>\n",
       "      <td>2024/09/06/14/28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12362 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Order_ID     VehicleID Sequence Stop_ID       ArrivalTime WaitingTime  \\\n",
       "0       O_1354     Veh1000_1        1     NaN   2024/09/01/5/30           0   \n",
       "1        O_587     Veh1000_1        2     NaN   2024/09/01/8/18           0   \n",
       "2        O_338     Veh1000_2        1     NaN   2024/09/01/5/30           0   \n",
       "3       O_1115     Veh1000_2        2     NaN   2024/09/01/5/30           0   \n",
       "4       O_1116     Veh1000_2        3     NaN   2024/09/01/5/30           0   \n",
       "...        ...           ...      ...     ...               ...         ...   \n",
       "12357   O_1328  Veh11000_102        3     NaN  2024/09/06/19/28           0   \n",
       "12358   O_2122  Veh11000_103        1     NaN   2024/09/06/5/30           0   \n",
       "12359   O_2328  Veh11000_103        2     NaN   2024/09/06/6/29           0   \n",
       "12360   O_2046  Veh11000_103        3     NaN  2024/09/06/16/10           0   \n",
       "12361    O_497  Veh11000_104        1     NaN  2024/09/06/14/00           0   \n",
       "\n",
       "       UnloadingTime DeaprtureTime  StopID     DepartureTime  \n",
       "0               15.0           NaN   S_986   2024/09/01/5/45  \n",
       "1                8.0           NaN   S_986   2024/09/01/8/26  \n",
       "2               10.7           NaN   S_575   2024/09/01/5/41  \n",
       "3                8.4           NaN   S_575   2024/09/01/5/38  \n",
       "4                7.1           NaN   S_575   2024/09/01/5/37  \n",
       "...              ...           ...     ...               ...  \n",
       "12357            0.0           NaN   S_712  2024/09/06/19/28  \n",
       "12358            0.0           NaN  S_1082   2024/09/06/5/30  \n",
       "12359            0.0           NaN   S_994   2024/09/06/6/29  \n",
       "12360            0.0           NaN   S_610  2024/09/06/16/10  \n",
       "12361           28.3           NaN   S_587  2024/09/06/14/28  \n",
       "\n",
       "[12362 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_result_dfs = [order1_result, order2_result, order3_result, order5_result, order11_result]\n",
    "order_result = pd.concat(order_result_dfs, ignore_index=True)\n",
    "\n",
    "order_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "user_home = os.path.expanduser('~')\n",
    "desktop_path = os.path.join(user_home, 'Desktop')\n",
    "\n",
    "\n",
    "output_path = os.path.join(desktop_path, 'Order_Result.csv')\n",
    "\n",
    "\n",
    "order_result.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
